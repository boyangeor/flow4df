<html>
  <body>
    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
      <div class="mermaid">
    
        classDiagram
          class Table {
            column_types
            is_active : bool
            location
            partition_spec : PartitionSpec
            storage : Storage
            storage_stub : Storage
            table_format : TableFormat
            table_identifier : TableIdentifier
            table_schema : StructType
            transformation
            upstream_tables : list[Table]
            as_batch_df(spark: SparkSession | None, options: dict[str, Any] | None) DataFrame
            as_streaming_df(spark: SparkSession | None, options: dict[str, Any] | None) DataFrame
            build_next_data_interval(spark: SparkSession | None) flow4df.DataInterval
            calculate_table_stats(spark: SparkSession) TableStats
            find_table_in_module(module: ModuleType) Table | None
            get_column_stats(column_name: str, spark: SparkSession | None) ColumnStats
            get_last_batch_data_interval(spark: SparkSession | None) flow4df.DataInterval
            get_upstream_table(name: str) Table
            init_table(spark: SparkSession) None
            init_table_stub(spark: SparkSession) None
            is_initialized_only(spark: SparkSession | None) bool
            run(spark: SparkSession | None, trigger: flow4df.Trigger | None, data_interval: flow4df.DataInterval | None) StreamingQuery | None
            run_table_maintenance(spark: SparkSession, run_for: dt.timedelta | None) None
            test_transformation(spark: SparkSession, data_interval: flow4df.DataInterval | None) None
          }
          class Transformation {
            build_next_data_interval(spark: SparkSession, this_table: Table) flow4df.DataInterval | None
            run_transformation(spark: SparkSession, this_table: Table, trigger: flow4df.Trigger | None, data_interval: flow4df.DataInterval | None) StreamingQuery | None
            test_transformation(spark: SparkSession, this_table: Table, trigger: flow4df.Trigger | None, data_interval: flow4df.DataInterval | None) None
          }
          class UnitTestTable {
            from_table(table: Table) UnitTestTable
          }
          UnitTestTable --|> Table
          Transformation --* Table : transformation
  
       </div>
  </body>
</html>
